<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <title>Bots, Seeds and People</title>
    <meta name="description" content="Slides for my paper about appraisal in Web archives.">
    <meta name="author" content="Ed Summers">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/white.css" id="theme">
    <link rel="stylesheet" href="lib/css/zenburn.css">
    <style>
      a {
        text-decoration: none;
      }
      .reveal figcaption {
        font-size: 14pt;
      }
      .citations {
        text-align: left;
        font-size: 14pt;
      }
      .reveal sup { 
        font-size: 14pt;
        vertical-align: super;
      }
    </style>
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>

    <div class="reveal">

      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">

        <section>
          <h2>Bots, Seeds and People</h2>
          <h3>Web Archives as Infrastructure</h3>
          <br>
          <p style="font-size: 18pt">

            Ed Summers<br>
            University of Maryland<br>
            <a href="http://twitter.com/edsu">@edsu</a> / <a href="mailto:ehs@pobox.com">ehs@pobox.com</a>
            <br>
            <br>
            Ricardo Punzalan<br>
            University of Maryland<br>
            <a href="http://twitter.com/archivalflip">@archivalflip</a> / <a href="mailto:punzalan@umd.edu">punzalan@umd.edu</a>
            <br>
            <br>
            slides: <a href="http://bit.ly/bots-seeds-people">http://bit.ly/bots-seeds-people</a>
            <br>
            paper: <a href="https://arxiv.org/abs/1611.02493v1">https://arxiv.org/abs/1611.02493v1</a>
          </p>
          <aside class="notes">
            Hi, it's great to be here at CSCW. Let's get started.
          </aside>
        </section>

        <section>
          <h3>Overview</h3>
          <ul>
            <li>Appraisal in Web Archives</li>
            <li>Research Question</li>
            <li>Methodology</li>
            <li>Findings</li>
            <li>Future Work</li>
          </ul>
        </section>

        <section data-background="images/envelope.jpg">
          How much of the web is in the Internet Archive?<br><br>
          273,000,000,000 <sup>1</sup> / 1,000,000,000,000 <sup>2</sup> = .273 ???
          <br>
          <br>
          <br>
          <p style="font-size: 14pt; text-align: left; margin-left: 15%; margin-right: 15%;">
          1. Alpert, J. and Hajaj, N. (2008). <a href="https://googleblog.blogspot.com/2008/07/we-knew-web-was-big.html">We knew the web was big...  </a> Google.<br>
          2. Goel, V. (2016). <a href="https://blog.archive.org/2016/10/23/defining-web-pages-web-sites-and-web-captures/">Defining Web pages, Web sites and Web captures</a>. Internet Archive.<br>
          </p>
          <aside class="notes">
            So I'm curious, just by a show of hands, how many people have 
            heard about the Internet Archive before. How many of you had 
            occacsion to use it?
            <ul>
              <li>510 billion objects or web captures.</li>
              <li>361 million websites</li>
              <li>15 petabytes of storage</li>
            </ul>
            <p>
            David Rosenthal of Stanford University has predicted that by 
            2018 it will cost more than the total GWP (Gross World Product) 
            to store that year's data on Amazon S3.
            </p>
          </aside>
        </section>

        <section>
          <figure>
            <img alt="NYTimes" src="images/wayback2.png">
            <figcaption>
              <a href="https://web.archive.org/web/20160601000000*/https://nytimes.com">Archival coverage</a> of the NYTimes homepage in 2016.
            </figcaption>
            <aside class="notes">
              The Internet Archive uses automated agents, spiders or
              bots to automatically crawl the Internet and archive material.
              As you can see from their coverage of the NYTimes homepage
              for 2016. On December 13th there were 103 snapshots just
              of the homepage itself.
            </aside>
          </figure>
				</section>

        <section>
          <figure>
            <img alt="VK" src="images/wayback.png">
            <figcaption>
              <a href="http://web.archive.org/web/20140501000000*/https://vk.com/wall-57424472_7256">Archival coverage</a> of Igor Strelkov's VKontakte profile in 2014.
            </figcaption>
          </figure>
          <aside class="notes">
            This is the coverage for Igor Strelkov's profile page on VKontakte
            which is a popular Russian social media site. Strelkov is
            currently being sued by the families of 18 passengers on MH17
            because he gave the order to shoot down the civilian aircraft
            thinking it was a Ukrainian military plane. We only know
            of his role because he posted on VKontakte about shooting down the
            aircraft, but deleted his post and his account on learning that it
            was in fact a civilian aircraft.

            Anatol Shmelev is a research fellow, curator of the Russia and
            Eurasia Collection, and the project archivist for the Radio Free
            Europe/Radio Liberty Collection, at the Hoover Institution. 
            In mid-July you can that Anatol added this webpage to a list of 
            URLs to be routinely crawled by Archive-It to become par of a 
            Ukrainian Conflict collection.

            Archive-It: 400 partner organizations in 48 U.S. states
            and 16 countries worldwide.
          </aside>
				</section>

        <section style="text-align: center;">
          <div style="text-align: left; width: 70%; margin-left: 15%;">
          <h2>Appraisal</h2>
          <p>The process of identifying materials offered to an archives that
          have sufficient <em>value</em> to be accessioned.</p>
          <br>
          <p style="font-size: 14pt;">
          <a href="http://www2.archivists.org/glossary/terms/a/appraisal">Appraisal</a> in <em>A Glossary of Archival and Records Terminology.</em> Society of American Archivists.
          </p>
          </div>
          <aside class="notes">
            <p>
            For over a hundred years Archivists have developed appraisal theory
            which provides practical guidance on the selection of material for 
            archives. Appraisal theories have often been pragmatic in nature, 
            because they are anchored in the contingencies of printing and 
            publishing technologies available at the time.
            </p>
            <p>
            As we just saw in previous examples these theories are now being 
            adapted to the web environment. Some appraisal decisions are enacted
            by archivists making selection decisions, and others are being
            inscribed in software (as in the case of the NYTimes) and attached
            to external data flows.
            </p>
          </aside>
        </section>

        <section>
          <h2>
          RQ: How is appraisal being enacted in <em>web</em> archives?
          </h2>
          <ul>
            <li>Selection strategies in web archiving</li>
            <li>Socio-technical factors that influence
              selection practices</li>
          </ul>
          <aside class="notes">
            <p>
            This leads me to our research question of how appraisal is
            being enacted in web archives. Currently the process is a
            blackbox. The collaboration between human and automated agents 
            forms a socio-technical system. We wanted to unlock the dynamic
            in order to inform selection strategies in web archiving, and
            also to better understand the sociotechnical environment of 
            web archiving, to hopefully inform the design and implementation
            of such systems.
            </p>
          </aside>
        </section>

        <section>
          <div class="citations">
            Kitchin, R. (2016). Thinking critically about and researching algorithms. <em>Information, Communication &amp; Society,</em> 1–16.
          </div>
          <br>
          <ol>
            <li>Source Code</li>
            <li>Reflexively producing code</li>
            <li>Reverse engineering</li>
            <li>Design &amp; designers</li>
            <li style="color: red;">Socio-technical assemblage</li>
            <li style="color: red;">The world</li>
          </ol>
          </p>
          <aside class="notes">
            <p>
            One important touchstone in our research is Rob Kitchin's
            framework for thinking crtitical thinking about algorithms. He 
            synthesizes much of the work being done in algorithm studies by 
            folks like Nick Diakopoulos, Stuart Geiger, Nick Seaver, 
            Tarleton Gillespie, Andrew Galloway and others to identify 
            various levels at which you can study algorithmic systems, and
            methodologies for studying them. In our study we were particularly
            interested in the socio-technical assemblage of web archiving, and
            how it is being used by archivists for which Kitchin suggests
            ethnography and interviews as useful.
            </p>
          </aside>
        </section>

        <section>
          <h3>Methodology</h3>
          <ul style="list-style: none;">
            <li class="fragment">39 contacted (email)</li>
            <li class="fragment">33 responded</li>
            <li class="fragment">28 interviewed</li>
            <li class="fragment">F (13) / M (15)</li>
            <li class="fragment">university, non-profit, library/museum</li>
            <li class="fragment">archivists, developers, researchers</li>
            <li class="fragment">semi-structured interviews</li>
            <li class="fragment"><img class="plain" width="150" src="images/skype.jpg"></li>
            <li class="fragment">memoing + field notes</li>
            <li class="fragment">coding / thematic analysis</li>
          </ul>
          <aside class="notes">
            <p>
            Started with people from the Web Archives 2015: Capture, Curate 
            and Analyze conference at the University of Michigan. And did
            snowball sampling from there.
            </p>
            <p>
              The process of inductive thematic analysis performed in this
              study relied on the use of field notes and personal memos.
              The analysis began by reading all the field notes to-
              gether, and then returning to do line by line coding. While
              coding was done without reference to an explicit theoretical
              framework, it was guided by our own interest in appraisal
              theory as a sociotechnical system that entangles the archivist
              with the material of the web and automated agents. 
              I will now describe these these themes:
            </p>
          </aside>
        </section>

        <section>
          <h3>Findings</h3>
          <img class="stretch" src="images/sociotechnical.png">
          <aside class="notes">
            During coding and analysis of our field notes we were able to 
            extract six general themes. The themes were interconnected and 
            interdependent, and fell into roughly two groups, the social and 
            the technical which you see pictured here in different colors. 
            They gave us a picture of the socio-technical environment of 
            appraisal in web archives.</p>
            <p>
            The picture is a bit of a tangled
            hairball, but this speaks to what Kitchin calls the data 
            assemblage: "that encompasses all of the technological, 
            political, social and economic apparatuses and elements that 
            constitutes and frames the generation, circulation and 
            deployment of data." in this case, web archive data.
            </p>
          </aside>
        </section>

        <section>
          <h3>Technical</h3>
          <img style="float: left;" src="images/technical.png">
          <div style="font-size: 24pt">
          <b>Crawl Modalities</b><br>
          domains, websites, topics, events, documents<br>
          <br>
          <b>Information Structures</b> <br>
          hierarchies, networks, streams<br>
          <br>
          <b>Tools</b><br>
          services, storage systems, open source utilities, spreadsheets, 
          forms, email, issue trackers
          </div>
          <aside class="notes">
            <p>
            First I will take a look at the technical themes.
            </p>
            <p>We see them
            grouped here. Crawl modalities refers to the selection 
            strategies implemented in web archiving tools and chosen by 
            archivists in their work. 
            </p>
            <p>
            Information structures refers to specific formations of web 
            content that archivists interacted with using their tools. 
            Deepwater Horizon Oil Spill
            </p>
            <p>
            And tools refers to the specic tools that they used to carry
            out the process of selection. 
            </p>
          </aside>
        </section>

        <section>
          <h3>Social</h3>
          <img style="float: left;" src="images/socio.png">
          <div style="font-size: 24pt;"> 
            <b>People</b><br>
            teams, lone-arrangers, developers, collaborations<br>
            <br>
            <b>Time</b><br>
            limits, scheduling, always-on, reading, reviewing<br>
            <br>
            <b>Money</b><br>
            grants, subscriptions, infrastructure<br>
          </div>
          <aside class="notes">
            <p>Our interviews also uncovered some expected grouping
            of social entities that were involved in the selection 
            of web content for archiving</p>
            <p>The first obvious one are people: who sometimes were teams
            (managers, field archivists and technicians), other times
            individuals working by themselves (lone arrangers), developers
            contributing to opensource projects and volunteer organizations
            such as ArchiveTeam. There were also organizational collaborations
            such as the IIPC that provided a setting for web archiving to take
            place.</p>
            <p>In our paper we lumped time and money together, but I've 
            separated them here in the diagram because they really are 
            different. They were interesting because of the way they abstract,
            commensurate and make appraisal decisions legible.</p>
            <p>Time was made manifest in schedules for how often to 
            archive particular sites, how long to perform a particular crawl
            operations, how quickly archival captures needed to be performed.</p>
            <p>
            Money or financial resources were often mentioned in terms
            of grant money from foundations and agencies for building 
            collections, subscription fees for services, and the relationship
            between money and storage.
            </p>
          </aside>
        </section>

        <section>
          <h3>Breakdown &amp; Repair</h3>
          <img class="stretch" src="images/sociotechnical.png">
          <aside class="notes">
            <p>
            Infrastructural inversion (Bowker) -- foregrounding background
            elements of work practice.
            </p>
            <p>
            Breakdown and repair are another theme that emerged during our 
            analysis, which can be seen in the many tangled connections in 
            the diagram. I'm thinking of work in infrastructure studies where 
            breakdown is used as a way to identify relationships in otherwise
            boring, mundane and consequently invisible systems (Star). And by
            repair I'm invoking some of the recent work by Steven Jackson
            who identifies sites of breakdown as opportunities for repair and
            more importantly design and innovation.
            </p>
            <p>
            Breakdowns between People and Tools could be seen in the use of 
            external tools such as email, spreadsheets, forms to provide
            missing features such as documenting provenance for 
            communication and collaboration in web archiving tools. 
            </p>
            <p>
            Breakdowns in the relationship between crawling modalities and
            information structures could be seen in topical collections. 
            For example a collaborative focus on Fracking by 
            archivists in NY and PA, were problematized when corporations 
            extended across state boundaries and internationally. Where should
            the scope of collection end? The archivists improvised
            communication tools to track selection.
            </p>
            <p>
            There were also breakdowns in legibility where archivists were not
            able to beforehand determine the extent of websites, and used test
            crawls in Archive-It to try to determine the size of websites by
            crawling for a period of time and examining how many URLs were 
            left uncrawled using host reports. They adjusted scoping rules
            in order to eliminate redundant content or deep wells of data that
            they weren't adequately funded to collect.
            </p>
            <p>
            Breakdown and repair is fundamental to the archival enteprirse 
            which is ultimately an ongoing process of repairing documentary
            breakdowns, in order to shape our knowldge of the past, and 
            social memory.
            </p>
          </aside>
        </section>

        <section>
          <h3>Future Work</h3>
          <div class="citations">
            Kitchin, R. (2016). Thinking critically about and researching algorithms. <em>Information, Communication &amp; Society,</em> 1–16.
          </div>
          <br>
          <ol>
            <li style="color: red;">Source Code</li>
            <li style="color: red;">Reflexively producing code</li>
            <li style="color: red;">Reverse engineering</li>
            <li style="color: red;">Design &amp; designers</li>
            <li>Socio-technical assemblage</li>
            <li>The world</li>
          </ol>
          <aside class="notes">
            <ul>
              <li>Trace ethnography work with Internet Archive's
                save-page-now functionality</li>
              <li>Take a closer look at the ways in which tools are used to
                repair web archiving systems</li>
              <li>Case studies with some of my informants to take a much
                deeper dive into actual practices that are used by
                web archivists.</li>
              <li>Interviews with designers of web archiving systems,
                specifically ones who implemented algorithms or data flows
                for appraisal</li>
              <li>Look at use of the Internet Archive, and other web archives:
                by journalists, lawyers and historians</li>
            </ul>
          </aside>
        </section>

        <section>
          <h1>Thanks!</h1>
          <figure>
            <a href="https://www.flickr.com/photos/derek_b/2599138046/"><img
              style="width: 70%" src="images/repair.jpg"></a>
            <figcaption>
              <a href="https://www.flickr.com/photos/derek_b/2599138046/">fix-it</a> by <a href="https://www.flickr.com/photos/derek_b/">Derek Bridges</a>
            </figcaption>
          </figure>
        </section>

        <section>
          <h1>Extras</h1>
          <ul>
            <li><a href="codebook.pdf">Codebook</a></li>
            <li><a href="questions.pdf">Interview Questions</a></li>
        </section>

        <section>
          <figure>
            <img src="images/seedlist.png">
            <figcaption>
              An example of a seed list from <a href="https://archive-it.org">Archive-It</a>
            </figcaption>
          </figure>
          <aside class="notes">
            <p>
            The seed list is a singular technical artifact in the appraisal
            of web content since it provides a list of resources to be 
            archived by software agents responsible for fetching and saving 
            the content. Sometimes archivists put URLs on these lists, and
            sometimes other software puts URLs on them.
            </p>
          </aside>
        </section>

        <section>
          <p>Star, S. L. (1999). The ethnography of infrastructure. American
          behavioral scientist, 43(3): 377– 391.</p>
          <ul style="font-size: 18pt;">
            <li><b>Embededness</b>: infrastructure is part of other structures,
              arrangements, and technologies</li>
            <li><b>Transparency</b>: infrastructure is transparent to use</li>
            <li><b>Reach/Scope</b>: infrastructure has reach beyond a particular
              site or event</li>
            <li><b>Learned as part of membership</b>: new participants acquire a
              naturalized familiarity with the objects of infrastructure</li>
            <li><b>Links with practice</b>: infrastructure is shaped by and also
              shapes communities of practice</li>
            <li><b>Standardization</b>: infrastructure achieves scope through
              approaches to standardization</li>
            <li><b>Built on installed base</b>: infrastructures are built upon
              layers of older base systems</li>
            <li><b>Becomes visible on breakdown</b>: the workings of
              infrastructure become visible when it breaks</li>
            <li><b>Is fixed incrementally</b>: changes and modifications are
              accreted over time, and not globally changed in one go</li>
          </ul>
        </section>

        <section>
          <p style="text-align: left;">
          It was part of that same sort of ecosystem of networks.
          It became clear to me through that process how impor-
          tant that network is becoming in collecting social move-
          ments moving forward. It was interesting watching peo-
          ple who had been doing collecting for decades in activist
          networks that they were a part of,  and then these new
          activist networks. . . there wasn’t a whole lot of overlap
          between them,  and where there was overlap there was
          often tension.  Unions really wanted in on Occupy and
          young people were a little bit wary of that. So social
          media networks became really important.
          </p>
        </section>

        <section>
          <p style="text-align: left;">
          I definitely remember there was a lot of trial and error.
          Because there’s kind of two parts. One of them is block-
          ing all those extraneous URLs, and there were also a lot
          of URLs that are on the example.edu domain that are ba-
          sically junk.
          </p>
        </section>

        <section>
          <p style="text-align: left;">
          The archiving is by the minute.  So if I post something,
          and then edit it in five minutes then it is archived again.
          If  someone  comments  on  something  and  then  another
          person comments it is archived again.  You don’t miss
          anything.   A lot of the other archiving companies that
          we’ve  talked  to  say  they  archive  a  certain  number  of
          times a day: maybe they archive at noon, and at 5, and at
          midnight, and there’s an opportunity to miss things that
          people deleted or hid.
          </p>
        </section>

        <section>
          <p style="text-align: left;">
          I went back to the developer and asked:  could you give
          me a tally of how many videos have had 10 views, how
          many videos have had 100 views and how many videos
          have had a 1000 views?  It turned out that the amount
          of videos that had 10 views or more was like 50-75 TB.
          And he told me that 50% of the videos, that is to say 500
          TB had never been viewed. They had been absorbed and
          then never watched.  A small amount had been watched
          when they were broadcast and never seen again.
          </p>
        </section>

      </div>

    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: false,
        progress: false,
        history: true,
        center: true,
        transition: 'fade', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
          { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
          { src: 'plugin/zoom-js/zoom.js', async: true },
          { src: 'plugin/notes/notes.js', async: true }
        ]
      });

    </script>

  </body>
</html>
